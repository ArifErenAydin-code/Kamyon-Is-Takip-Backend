from ultralytics import YOLO
import argparse
import sys
import torch
import cv2
import numpy as np
import re
from datetime import datetime
import easyocr as ocr
from PIL import Image

# EasyOCR baÅŸlatma - Ä°ngilizce ve TÃ¼rkÃ§e dil desteÄŸi
ocr_motoru = ocr.Reader(['en', 'tr'])

def print_separator():
    print("\n" + "="*50)
    print(f"ğŸ•’ {datetime.now().strftime('%H:%M:%S')}")
    print("="*50)

def validate_number(text):
    """Tespit edilen sayÄ±nÄ±n geÃ§erli bir tonaj deÄŸeri olup olmadÄ±ÄŸÄ±nÄ± kontrol eder"""
    try:
        # Sadece sayÄ±larÄ± al
        numbers = ''.join(filter(str.isdigit, text))
        
        # SayÄ± uzunluÄŸu kontrolÃ¼ (2-6 karakter arasÄ±)
        if len(numbers) < 2 or len(numbers) > 6:
            return False
            
        # SayÄ±ya Ã§evir
        value = int(numbers)
        
        # MantÄ±klÄ± tonaj aralÄ±ÄŸÄ± kontrolÃ¼ (100kg - 50000kg)
        if value < 100 or value > 50000:
            return False
            
        return True
    except:
        return False

def extract_text_from_box(image, box):
    """Tespit edilen kutu iÃ§indeki sayÄ±larÄ± Ã§Ä±karÄ±r"""
    try:
        print("      ğŸ“ KoordinatlarÄ± iÅŸleme...")
        # YOLO kutusunu al
        x1, y1, x2, y2 = map(int, box)
        
        print(f"      ğŸ“ YOLO kutu koordinatlarÄ±: x1={x1}, y1={y1}, x2={x2}, y2={y2}")
        
        print("      ğŸ” OCR uygulanÄ±yor...")
        
        # TÃ¼m gÃ¶rÃ¼ntÃ¼de OCR uygula
        results = ocr_motoru.readtext(image)
        
        best_result = None
        best_confidence = 0
        
        # Her tespit edilen metin iÃ§in
        for (bbox, text, confidence) in results:
            # bbox koordinatlarÄ±: [[x1,y1], [x2,y1], [x2,y2], [x1,y2]]
            text_x1 = int(min(point[0] for point in bbox))
            text_y1 = int(min(point[1] for point in bbox))
            text_x2 = int(max(point[0] for point in bbox))
            text_y2 = int(max(point[1] for point in bbox))
            
            # Tespit edilen metnin merkez noktasÄ±
            text_center_x = (text_x1 + text_x2) / 2
            text_center_y = (text_y1 + text_y2) / 2
            
            # Metin merkezi YOLO kutusunun iÃ§inde mi kontrol et
            if (x1 <= text_center_x <= x2 and y1 <= text_center_y <= y2):
                # Sadece sayÄ±larÄ± al
                numbers = ''.join(filter(str.isdigit, text))
                
                print(f"      ğŸ“ Kutu iÃ§inde tespit edilen metin: '{text}' -> SayÄ±lar: '{numbers}' (GÃ¼ven: {confidence:.2f})")
                print(f"      ğŸ“ Metin koordinatlarÄ±: x1={text_x1}, y1={text_y1}, x2={text_x2}, y2={text_y2}")
                
                # Sonucu deÄŸerlendir
                if numbers and validate_number(numbers) and confidence > best_confidence:
                    best_result = numbers
                    best_confidence = confidence
            else:
                print(f"      â© Kutu dÄ±ÅŸÄ±nda tespit: '{text}' (x={text_center_x:.1f}, y={text_center_y:.1f})")
        
        if best_result:
            print(f"      âœ… SayÄ± baÅŸarÄ±yla tespit edildi: {best_result} (GÃ¼ven: {best_confidence:.2f})")
            return best_result
            
        print("      âŒ GeÃ§erli sayÄ± tespit edilemedi")
        return ""
        
    except Exception as e:
        print(f"      âŒ OCR HatasÄ±: {str(e)}")
        return ""

def print_detection(box, names, image):
    cls = int(box.cls.item())
    conf = box.conf.item()
    xyxy = box.xyxy[0].tolist()
    
    print("\nğŸ“Œ TESPÄ°T DETAYLARI:")
    print(f"   ğŸ·ï¸  SÄ±nÄ±f: {names[cls]}")
    print(f"   ğŸ“Š GÃ¼ven: %{conf*100:.2f}")
    print(f"   ğŸ“ Konum: [x1={xyxy[0]:.1f}, y1={xyxy[1]:.1f}, x2={xyxy[2]:.1f}, y2={xyxy[3]:.1f}]")
    
    # Tespit edilen alanÄ±n boyutlarÄ±
    width = xyxy[2] - xyxy[0]
    height = xyxy[3] - xyxy[1]
    print(f"   ğŸ“ Boyut: {width:.1f}x{height:.1f} piksel")
    
    print("\n   ğŸ” OCR Ä°ÅLEMÄ° BAÅLIYOR...")
    # OCR ile metin Ã§Ä±kar
    text = extract_text_from_box(image, xyxy)
    if text:
        print(f"   âœ… OCR BAÅARILI - Tespit Edilen SayÄ±: {text}")
        # DATA: prefix'i ile Node.js'e gÃ¶nder
        print(f"DATA:{cls},{conf},{','.join(map(str, xyxy))},{text}")
    else:
        print(f"   âŒ OCR BAÅARISIZ - SayÄ± tespit edilemedi")
        print(f"DATA:{cls},{conf},{','.join(map(str, xyxy))}")
    print("   ğŸ” OCR Ä°ÅLEMÄ° TAMAMLANDI\n")

def extract_weight(text):
    """NET AÄIRLIK deÄŸerini metinden Ã§Ä±kar"""
    match = re.search(r'NET\s+AÄIRLIK\s*[:=]?\s*(\d+(?:[.,]\d+)?)\s*KG', text, re.IGNORECASE)
    if match:
        return float(match.group(1).replace(',', '.'))
    return None

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--source', required=True, help='Path to input image')
    parser.add_argument('--weights', required=True, help='Path to weights file')
    parser.add_argument('--conf', type=float, default=0.25, help='Confidence threshold')
    args = parser.parse_args()

    try:
        print_separator()
        print("ğŸš€ YOLO ANALÄ°ZÄ° BAÅLIYOR")
        print(f"ğŸ“¸ GÃ¶rÃ¼ntÃ¼: {args.source}")
        print(f"âš™ï¸  Model: {args.weights}")
        
        # YOLO modelini yÃ¼kle
        print("\nâŒ› Model yÃ¼kleniyor...")
        model = YOLO(args.weights)
        print("âœ… Model yÃ¼klendi")

        # GÃ¶rÃ¼ntÃ¼yÃ¼ oku
        print("\nâŒ› GÃ¶rÃ¼ntÃ¼ okunuyor...")
        image = cv2.imread(args.source)
        if image is None:
            raise ValueError("âŒ GÃ¶rÃ¼ntÃ¼ okunamadÄ±!")
        print(f"âœ… GÃ¶rÃ¼ntÃ¼ okundu: {image.shape}")

        # Tahmin yap
        print("\nâŒ› Analiz yapÄ±lÄ±yor...")
        results = model.predict(
            source=image,
            conf=args.conf,
            iou=0.3,
            save=True,
            save_txt=True,
            show=False,
            agnostic_nms=True,
            max_det=50,
            line_thickness=2,  # Kutu Ã§izgi kalÄ±nlÄ±ÄŸÄ±
            hide_labels=True,  # Etiketleri gizle
            hide_conf=True     # GÃ¼ven deÄŸerlerini gizle
        )
        print("âœ… Analiz tamamlandÄ±\n")

        # SonuÃ§larÄ± iÅŸle
        for result in results:
            boxes = result.boxes
            if len(boxes) == 0:
                print("âš ï¸  HiÃ§bir nesne tespit edilemedi!")
                continue

            print(f"\nğŸ¯ TOPLAM {len(boxes)} TESPÄ°T:")
            
            for i, box in enumerate(boxes, 1):
                print(f"\n--- TESPÄ°T #{i} ---")
                print_detection(box, result.names, image)

        print("\nâœ¨ GÃ¶rselleÅŸtirme kaydedildi:")
        print("ğŸ“ runs/detect/predict/")
        print_separator()
        
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ HATA: {str(e)}", file=sys.stderr)
        print_separator()
        sys.exit(1)

if __name__ == "__main__":
    main() 